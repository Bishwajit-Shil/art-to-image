{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization, UpSampling2D,Concatenate, Cropping2D, ZeroPadding2D\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import keras\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from IPython.display import clear_output\n",
    "import matplotlib\n",
    "seed = 2019\n",
    "np.random.seed = seed\n",
    "random.seed = seed\n",
    "tf.seed = seed\n",
    "path = '/home/karan/Desktop/Chandigarh_Police_Hackathon'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_id_list = train['image_id'].unique().tolist()\n",
    "image_id_list = os.listdir(path+'/celeb_sketch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_id_list = sum(image_id_list,[])\n",
    "print(len(image_id_list),image_id_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters    \n",
    "- image size\n",
    "- train path\n",
    "- epochs\n",
    "- validation size\n",
    "- Generator Declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (218,178)\n",
    "train_path = '/home/karan/Desktop/Chandigarh_Police_Hackathon'\n",
    "epochs = 30\n",
    "validation_size = 16\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self,ids,filepath,batch_size=16,image_size=(480,640),channels=3):\n",
    "        self.ids=ids\n",
    "        self.filepath=filepath\n",
    "        self.batch_size=batch_size\n",
    "        self.image_size=image_size\n",
    "        self.channels=channels\n",
    "        \n",
    "    def __len__(self):\n",
    "            return (len(self.ids)//self.batch_size)\n",
    "        \n",
    "    '''def __load__(self,id_name):\n",
    "            img = cv2.imread(filepath+'/'+id_name,-1)\n",
    "            img = cv2.resize(img,(self.image_size[0],self.image_size[1]))\n",
    "            return img'''\n",
    "            \n",
    "            \n",
    "            \n",
    "    def __getitem__(self,index):\n",
    "            indexes = range(index*self.batch_size,index*self.batch_size+self.batch_size)\n",
    "            \n",
    "            ids_to_load = [self.ids[k] for k in indexes]\n",
    "            X = self.__generate_x(ids_to_load)\n",
    "            y = self.__generate_y(ids_to_load)\n",
    "            l = []\n",
    "            for i,m in enumerate(X):\n",
    "                l.append(m.reshape(218,178,3))\n",
    "            X = np.array(l)\n",
    "            l = []\n",
    "            for i,m in enumerate(y):\n",
    "                l.append(m.reshape(218,178,3))\n",
    "            y = np.array(l)\n",
    "            return X,y\n",
    "            \n",
    "        \n",
    "        \n",
    "    def __generate_x(self,id_names):\n",
    "            X = np.zeros((self.batch_size,self.image_size[0],self.image_size[1],self.channels))\n",
    "            for i,id_n in enumerate(id_names):\n",
    "                #print(self.filepath+'/sketch/'+id_n+'-sz1.jpg')\n",
    "                img = cv2.imread(self.filepath+'/celeb_sketch/'+id_n)\n",
    "                '''plt.imshow(img)\n",
    "                plt.show()'''\n",
    "                img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "                img = img.astype(np.float32)/255.\n",
    "                \n",
    "                img = cv2.resize(img,(self.image_size[0],self.image_size[1]))\n",
    "                '''plt.imshow(img)\n",
    "                plt.show()'''\n",
    "                X[i,:,:,:] = img.reshape(self.image_size[0],self.image_size[1],self.channels)\n",
    "            return X\n",
    "        \n",
    "    def __generate_y(self,id_names):\n",
    "            y = np.zeros((self.batch_size,self.image_size[0],self.image_size[1],self.channels))\n",
    "            for i,id_n in enumerate(id_names):\n",
    "                img = cv2.imread(self.filepath+'/celeb/'+id_n)\n",
    "                img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "                img = img.astype(np.float32)/255.\n",
    "                img = cv2.resize(img,(self.image_size[0],self.image_size[1]))\n",
    "                '''plt.imshow(img)\n",
    "                plt.show()'''\n",
    "                y[i,:,:,:] = img.reshape(self.image_size[0],self.image_size[1],self.channels)\n",
    "            return y\n",
    "             \n",
    "        \n",
    "    ''' def __generate_y(self,id_names):\n",
    "            y = np.zeros((self.batch_size,self.image_size[0],self.image_size[1],4))\n",
    "            \n",
    "            for i,id_n in enumerate(id_names):\n",
    "                im_name = self.train[self.train['image_id'] == id_n]\n",
    "                rles = im_name['EncodedPixels'].values\n",
    "                #print(rles,np.array(rles).shape)\n",
    "                y[i,:,:,:] = build_masks(rles,(1400,2100),reshape=(self.image_size[0],self.image_size[1]))\n",
    "            \n",
    "            return y'''\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample plot of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = DataGenerator(image_id_list[:int(len(image_id_list)*0.2)],train_path,batch_size=16,image_size=(178,218),channels=3)\n",
    "val_gen = DataGenerator(image_id_list[int(len(image_id_list)*0.95):],train_path,batch_size=16,image_size=(178,218),channels=3)\n",
    "test_gen = DataGenerator(image_id_list[int(len(image_id_list)*0.25):int(len(image_id_list)*0.90)],train_path,batch_size=16,image_size=(178,218),channels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X,y = val_gen.__getitem__(1)\n",
    "val_gen.__len__()\n",
    "#train_gen.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(image_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('file.jpg',X[1]*255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='file.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X[1])\n",
    "plt.show()\n",
    "plt.imshow(y[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different Convolution block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crop_shape(target, refer):\n",
    "        # width, the 3rd dimension\n",
    "        cw = (target.get_shape()[2] - refer.get_shape()[2]).value\n",
    "        assert (cw >= 0)\n",
    "        if cw % 2 != 0:\n",
    "            cw1, cw2 = int(cw/2), int(cw/2) + 1\n",
    "        else:\n",
    "            cw1, cw2 = int(cw/2), int(cw/2)\n",
    "        # height, the 2nd dimension\n",
    "        ch = (target.get_shape()[1] - refer.get_shape()[1]).value\n",
    "        assert (ch >= 0)\n",
    "        if ch % 2 != 0:\n",
    "            ch1, ch2 = int(ch/2), int(ch/2) + 1\n",
    "        else:\n",
    "            ch1, ch2 = int(ch/2), int(ch/2)\n",
    "\n",
    "        return (ch1, ch2), (cw1, cw2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def down_block(x,filters,kernel_size=(3,3),strides=1,padding='same',activation='relu'):\n",
    "    c = Conv2D(filters,kernel_size=kernel_size,padding=padding,strides=strides,activation=activation)(x)\n",
    "    c = Conv2D(filters,kernel_size=kernel_size,padding=padding,strides=strides,activation=activation)(c)\n",
    "    p = MaxPooling2D((2,2))(c)\n",
    "    return c,p\n",
    "\n",
    "def up_block(x,skip,filters,kernel_size=(3,3),strides=1,padding='same',activation='relu'):\n",
    "    us = UpSampling2D((2,2))(x)\n",
    "    ch, cw = get_crop_shape(skip,us)\n",
    "    us = ZeroPadding2D(padding = (ch,cw))(us)\n",
    "    #ch, cw = get_crop_shape(skip,us)\n",
    "    #skip = Cropping2D(cropping=(ch,cw))(skip)\n",
    "    us = Concatenate()([us,skip])\n",
    "    us = Conv2D(filters,kernel_size,padding=padding,strides=strides,activation=activation)(us)\n",
    "    us = Conv2D(filters,kernel_size,padding=padding,strides=strides,activation=activation)(us)\n",
    "    return us\n",
    "    \n",
    "def bottleneck(x,filters,kernel_size=(3,3),strides=1,padding='same',activation='relu'):\n",
    "    b = Conv2D(filters,kernel_size,padding=padding,strides=strides,activation=activation)(x)\n",
    "    b = Conv2D(filters,kernel_size,padding=padding,strides=strides,activation=activation)(b)\n",
    "    return b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Unet():\n",
    "    f = [16,32,64,128,256]\n",
    "    inputs = Input((image_size[0],image_size[1],3))\n",
    "    \n",
    "    c1,p1 = down_block(inputs,f[0])#350->175, 525->262\n",
    "    c2,p2 = down_block(p1,f[1])#175->87, 262-> 131\n",
    "    c3,p3 = down_block(p2,f[2])#87->43, 131 -> 65 \n",
    "    c4,p4 = down_block(p3,f[3])#43->21, 65->32\n",
    "    b = bottleneck(p4,f[4])#21,32\n",
    "    u1 = up_block(b,c4,f[3])#\n",
    "    u2 = up_block(u1,c3,f[2])#16->32\n",
    "    u3 = up_block(u2,c2,f[1])#32->64\n",
    "    u4 = up_block(u3,c1,f[0])#64->128\n",
    "    \n",
    "    outputs = Conv2D(3,(1,1),padding='same',activation='sigmoid')(u4)\n",
    "    \n",
    "    model = Model(inputs,outputs)\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Unet()\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=[dice_loss])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(train_gen.__len__()):\n",
    "    X,y = train_gen.__getitem__(i)\n",
    "    loss = model.train_on_batch(X,y)\n",
    "    print('loss:',loss)\n",
    "    val_x,val_y = val_gen.__getitem__(i)\n",
    "    pred_y = model.predict(val_x)\n",
    "    plt.imshow(pred_y[0])\n",
    "    plt.title('Predicted')\n",
    "    plt.show()\n",
    "    plt.imshow(val_y[0])\n",
    "    plt.title('Expected')\n",
    "    plt.show()\n",
    "    #clear_output(wait=True)\n",
    "#model.fit_generator(train_gen,epochs = epochs,validation_data = val_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('model.h5', save_best_only=True)\n",
    "checkpoint2 = ModelCheckpoint(\"best_model.hdf5\", monitor='loss', verbose=1,save_weights_only =True,\n",
    "    save_best_only=True, mode='auto', period=1)\n",
    "history = model.fit_generator(train_gen,epochs = epochs,validation_data = val_gen,callbacks=[checkpoint2,checkpoint])\n",
    "with open('history.pickle','wb') as file:\n",
    "    pickle.dump(history.history,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('image.png')\n",
    "img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "img = cv2.resize(img,(178,218))\n",
    "img = img.astype(np.float32)/255.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dodgeV2(image, mask):\n",
    "    return cv2.divide(image, 255-mask, scale=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def burnV2(image, mask):\n",
    "    return 255 - cv2.divide(255-image, 255-mask, scale=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "#ret,thresh1 = cv2.adaptiveThreshold(img,0.60,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,11,2)\n",
    "img = cv2.threshold(img,0.6,1,cv2.THRESH_BINARY)[1]\n",
    "'''img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "img_gray_inv = 255 - img_gray\n",
    "img_blur = cv2.GaussianBlur(img_gray_inv, ksize=(21, 21),sigmaX=0, sigmaY=0)\n",
    "img_blend = dodgeV2(img_gray, img_blur)\n",
    "img = cv2.cvtColor(img_blend,cv2.COLOR_GRAY2RGB)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_sharpening = np.array([[-1,-1,-1], \n",
    "                              [-1, 9,-1],\n",
    "                              [-1,-1,-1]])\n",
    "sharpened = cv2.filter2D(img, -1, kernel_sharpening)\n",
    "dst = cv2.fastNlMeansDenoisingColored(img,None,10,10,7,21)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = val_gen.__getitem__(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = model.predict(X)\n",
    "y_pred = model.predict(img.reshape(1,218,178,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X,y = test_gen.__getitem__(7)\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "    f,ax = plt.subplots(1,3)\n",
    "    ax[0].imshow(X[i])\n",
    "    ax[0].set_title('Input')\n",
    "    ax[1].imshow(y_pred[i])\n",
    "    ax[1].set_title('Predicted')\n",
    "    ax[2].imshow(y[i])\n",
    "    ax[2].set_title('Expected')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('history.pickle','rb') as file:\n",
    "    history = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('model.h5',custom_objects={'dice_loss':dice_loss})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(img.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "plt.imshow(y_pred.reshape(218,178,3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.image.imsave('mypic.png',y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
